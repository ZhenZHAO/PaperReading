annotation-efficient, less-anotation data

<img src="../imgs/small data.jpg" alt="small data" style="zoom:50%;" />

> “Small Data Challenges in Big Data Era: A Survey of Recent Progress on Unsupervised and Semi-Supervised Methods"

## TO DO

- 1 Learning From less-annotation data
  - Semi-supervised learning
  - Self-supervised learning
  - Few-shot learning
  - Meta-learning
  - Domain Adaptation
  - Domain Generalization
  - GAN-assisted
- 2 Few shot segmentation

## 1 Learning From less-annotation data

### 1.1 Semi-supervised learning

> 少量有带标签的样本和大量无标签的样本, 并且unlabeled data的数量要远大于labeled data

### 1.2 Self-supervised learning

- 自监督来说它使用的数据本身是没有标签的，但是我们后面自己设计标签**设计任务**来帮助模型学习到数据里面的一些特征，然后利用这些特征再去进行更多的下游任务。i.e., 对于输入的一堆无监督的数据，通过数据本身的结构或者特性人为构造标签，之后类似监督学习一样进行训练。所以对于自监督学习来说，存在三个挑战：

  - 对于大量的无标签数据，如何进行表征学习？
  - 从数据的本身出发，如何设计有效的辅助任务 pretext？
  - 对于自监督学习到的表征，如何来评测它的有效性？ --> 同监督学习类似，由一些下游任务的性能来体现

- 通常有以下的方法:

  - 基于上下文（Context based）

    - >  基于数据本身的上下文信息，提出一些Pre-Task来辅助网络学习数据的特征

    - Jigsaw（拼图) 任务

      - Carl Doersch, Abhinav Gupta, and Alexei A. Efros. Unsupervised Visual Representation Learning by Context Prediction. In ICCV 2015

    - Inpainting（抠图） 任务

      - Deepak Pathak et al. Context Encoders: Feature Learning by Inpainting. In CVPR 2016.

    - 图片的颜色信息
      
      - Zhang, R., Isola, P., & Efros, A. A. Colorful image colorization. In ECCV 2016.
    - Rotation （旋转）
      
      - 类似数据增广的方式来寻找自监督上下文
    - Gidaris, Spyros et al. “Unsupervised Representation Learning by Predicting Image Rotations.” In ICLR 2018
  
- 基于时序（Temporal Based）
  
    - 基于时序的方法将注意力放到了数据的时间序列特征上面，这就需要我们来使用具有时间序列特点的数据.
  - 明显适用于，视频和自然语言
  
- 基于对比（Contrastive Based）
  
  - 最近比较流行，且效果很好 (跟 metric learning 啥区别?)
  
  - 这种方法的核心其实就是如何来构建正负样本，然后通过最大化正负样本的距离来实现自监督学习。这里问题的核心就是正样本的距离要远远大于负样本的距离，
  
    <img src="https://img-blog.csdnimg.cn/20200531152750103.png" style="zoom:80%;" />
  
  - 这里的 x 通常也称为 「anchor」数据，为了优化 anchor 数据和其正负样本的关系，我们可以使用点积的方式构造距离函数，然后构造一个 softmax 分类器，以正确分类正样本和负样本。这应该鼓励相似性度量函数（点积）将较大的值分配给正例，将较小的值分配给负例.
  
- DIM
  
  - Hjelm, R. Devon et al. “Learning deep representations by mutual information estimation and maximization.” . ICLR 2019
  
- CPC
  
  - Oord, Aäron van den et al. “Representation Learning with Contrastive Predictive Coding.”
  
- 多模态（多视角）的信息来构造样本
  
    - 一个样本的多个模态为正样本，其他样本的模态为负样本 
  - Tian, Yonglong et al. “Contrastive Multiview Coding.” ArXiv abs/1906.05849 (2019): n. pag.
  
- memory bank
  
  - Wu, Zhirong et al. “Unsupervised Feature Learning via Non-parametric Instance Discrimination.” CVPR 2018
  
- Moco
  
  - He, Kaiming et al. “Momentum Contrast for Unsupervised Visual Representation Learning.” ArXiv abs/1911.05722 (2019): n. pag.
  
- SimCLR
  
    - Chen, Ting et al. “A Simple Framework for Contrastive Learning of Visual Representations.” ArXiv abs/2002.05709 (2020): n. pag.



